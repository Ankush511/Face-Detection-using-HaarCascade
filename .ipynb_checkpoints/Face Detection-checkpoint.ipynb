{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f432a7-ec7f-42df-96a0-677e4855c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1933d-0d17-44fa-8611-bb0c722cd23d",
   "metadata": {},
   "source": [
    "## <b/> 1. Detect Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec33c9e-8429-4bac-9a69-2b5fe065cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1322.298] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    _, img = cam.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    try:\n",
    "        faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0,180,0), 2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('Frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4d63-4421-41a9-8b50-7cb3c9911154",
   "metadata": {},
   "source": [
    "## <b/> 2. Crop Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44987a2-b1f6-416d-a6c4-acf12f4eaf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2.158] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "2024-09-12 15:09:46.184 python[37429:7626621] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-09-12 15:09:47.762 python[37429:7626621] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-09-12 15:09:47.762 python[37429:7626621] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:                             # Going through Each Face Detected\n",
    "        if f[-1] == max(faces[:,-1]):           # Finding the Face with Maximum Area\n",
    "            break \n",
    "\n",
    "    if (len(faces) >= 1):                       # Drawing Rectange on the Face\n",
    "        x = f[0] \n",
    "        y = f[1] \n",
    "        w = f[2]\n",
    "        h = f[3]\n",
    "\n",
    "    cv2.rectangle(img, (x,y),(x+w,y+h) , (0,180,0), 2)   \n",
    "    face = img[y:y+h, x:x+w]\n",
    "        \n",
    "    face = cv2.resize(face, (256,256))\n",
    "\n",
    "    cv2.imshow('Frame'  , img )\n",
    "    cv2.imshow('Face'   , face)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003dea4e-5d78-40eb-80d8-db3b488591c7",
   "metadata": {},
   "source": [
    "## <b/>3. Realtime Face Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7454b3-6f75-4408-baaf-6061fb00a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@28829.308] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    if (len(faces) >= 1):\n",
    "        x = f[0] \n",
    "        y = f[1] \n",
    "        w = f[2]\n",
    "        h = f[3]\n",
    "\n",
    "        face = img[y:y+h, x:x+w]                 # Getting the Face Area from Video Feed\n",
    "        face = cv2.blur(face, (32,32))            # Applying Blur on the Face\n",
    "        img[y:y+h, x:x+w] = face                 # Apply Blured Face on Video Feed\n",
    "        \n",
    "\n",
    "    cv2.imshow('Frame'  , img )\n",
    "    cv2.imshow('Face'   , face)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f43b0-f989-4c15-b748-4213975943cc",
   "metadata": {},
   "source": [
    "## <b/> 4. Realtime Face Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555878f4-c5fa-4f49-a1e7-91356d1d82b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@29247.727] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "## Square Black\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    x = f[0] \n",
    "    y = f[1] \n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    \n",
    "    black = np.zeros((face.shape), dtype = int)\n",
    "    \n",
    "    img[y:y+h, x:x+w] = black\n",
    "\n",
    "    cv2.imshow('Frame'  , img )\n",
    "    cv2.imshow('Face'   , face)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e177025-3114-4471-9be3-e02cd8a437d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@29338.391] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "## Circle Black\n",
    "\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    x = f[0] \n",
    "    y = f[1] \n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "    \n",
    "    circle_x = x + int(w/2)\n",
    "    circle_y = y + int(h/2)\n",
    "    \n",
    "    cv2.circle(img, (circle_x, circle_y), int(w/1.7), (110,180,68),-1)\n",
    "\n",
    "    cv2.imshow('Frame'  , img )\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bed2a-5872-4dd9-bd51-86c7760cfd4b",
   "metadata": {},
   "source": [
    "## <b/>5. Face Extraction From Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a717b627-c403-4680-8483-82a2f1f4ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 00:02:59.516 python[44779:7740218] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-09-13 00:02:59.516 python[44779:7740218] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People/IMG_2.png is exported\n",
      "People/IMG_3.png is exported\n",
      "People/IMG_4.png is exported\n",
      "People/IMG_5.png is exported\n",
      "People/IMG_6.png is exported\n",
      "People/IMG_7.png is exported\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('group.png')\n",
    "\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "\n",
    "def save(frame, folder_name): \n",
    "    name_img = len(os.listdir(folder_name)) + 1\n",
    "    name_img = folder_name + \"/IMG_\" + str(name_img) + '.png'\n",
    "    cv2.imwrite(name_img, frame)\n",
    "    print(name_img ,'is exported')\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    cv2.imshow('Face'   , face)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(0) == 13:         # Save the Image | 13  = Enter Key\n",
    "        save(face, 'People')\n",
    "    \n",
    "    elif cv2.waitKey(0) == 127:      # Skip the Image | 127 = Delete Key\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57866a7-ad15-4361-879a-e0c2772a40e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
